import os
import sys
import requests
import json
from datetime import datetime, timedelta
from zipfile import ZipFile
import argparse
from tqdm import tqdm
import subprocess
import re


# constants
MB_password = 'infected'


def get_previous_date():
    # Since we might run this in the evening, MB may not have a daily files for today's date, thus previous date.
    previous_date = (datetime.today() - timedelta(days=1)).strftime('%Y-%m-%d')
    return previous_date


def query_mb_hash(hash_sent, output_save):
    """ Slightly cursed since older version required Twitter access for API key """
    headers = {'API-KEY': ''}
    try:
        _filepath = output_save + '/' + hash_sent + '.json'
        output_save = os.path.normpath(_filepath)
        session = requests.Session()
        _post_data = {'query': 'get_info', 'hash': hash_sent}
        response = session.post('https://mb-api.abuse.ch/api/v1/', headers=headers, data=_post_data)
        print("[+] Querying for %s" % hash_sent) 
        if response.status_code == 200:
            if response.json()["query_status"] == 'hash_not_found':
                print('>>  The sample hash was not found on MalBazaar  <<')
            else:
                json_response = response.json()
                print("[+] Saving to %s" % output_save)
                with open(output_save, "w") as json_save:                    
                    json_save.write(json.dumps(json_response))
                pretty_object = json.dumps(json_response, indent=4, sort_keys=True)
                print(pretty_object)
        else:
            print(response.status_code)
            print(response.json())
    except Exception as query_error:
        print("[!] query error on request: %s" % query_error)


def pull_mb_samples(file_path):
    previous_date = get_previous_date()
    _out_file = file_path + "MB-" + previous_date + ".zip"
    if os.path.exists(_out_file):
        print("[!] Daily File already present, skipping pull going to extract")
        return _out_file
    else:
        try:
            session = requests.Session()
            response = session.head('https://datalake.abuse.ch/malware-bazaar/daily/' + previous_date + '.zip')
            if response.status_code == 200:
                print("[+] I was able to find a sample pack from MB using the %s provided" % previous_date)
                print("[+] File is approximately %s in size" % response.headers['Content-length'])
                try:
                    session = requests.Session()
                    print("[+] Pulling back file " + previous_date + '.zip')
                    fetch = session.get('https://datalake.abuse.ch/malware-bazaar/daily/' + previous_date + '.zip',
                                        stream=True)

                    total = int(fetch.headers.get('content-length', 0))

                    with open(_out_file, "wb") as progress, tqdm(desc=_out_file, total=total, unit='iB', unit_scale=True,
                                                          unit_divisor=1024) as bar:

                        for data in fetch.iter_content(chunk_size=1024):
                            size = progress.write(data)
                            bar.update(size)

                    print("[+] I was able to pull back a sample pack from MB using the %s provided" % previous_date)
                    return _out_file
                except Exception as fetch_error:
                    print("[!] query error on request: %s" % fetch_error)
            else:
                print(response.status_code)
                print(response.json())
        except Exception as pull_error:
            print("[!] query error on request: %s" % pull_error)


def get_zip_contents(file_name):
    print("[+] I extract the file provided %s provided" % file_name)
    _path = os.path.dirname(file_name)
    _exe_list = []
    _dll_list = []

    with subprocess.Popen(['7z', 'l', file_name], stdout=subprocess.PIPE, text=True) as proc:
        for line in proc.stdout:
            match = re.search(r'\s(\S+\.exe)$', line)
            if match:
                _exe_list.append(match.group(1))
            match = re.search(r'\s(\S+\.dll)$', line)
            if match:
                _dll_list.append(match.group(1))

    file_to_extract = len(_exe_list) + len(_dll_list)
    print("[+] Found {} exe files and {} dll files to extract".format(len(_exe_list), len(_dll_list)))

    with tqdm(total=file_to_extract, desc="Extracting", unit="file") as pbar:
        for file in _exe_list + _dll_list:
            subprocess.run(['7z', 'e', file_name, file, f'-o{_path}', f'-p{MB_password}', '-y'], check=True)
            pbar.update(1)

    return _exe_list, _dll_list


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-p', dest='pull', help='Pull Files, -p FilePath in quotes', type=str)
    parser.add_argument('-q', dest='hash_info', help='Query MB using hash info, -q in md5/sha1/sha256 format', type=str)
    parser.add_argument('-o', dest='output', help='Save output to location, -o FilePath in quotes', type=str, default=(os.getcwd()))
    options = parser.parse_args()
    pull_samples = options.pull
    hash_stdin = options.hash_info
    output_save = options.output
    if hash_stdin:
        print("Output will save to %s" % output_save)
        query_mb_hash(hash_stdin, output_save)
        sys.exit(0)
    if pull_samples:
        if not os.path.exists(pull_samples):
            os.mkdir(pull_samples)
        pull_samples = os.path.join(pull_samples, '')
        out_file = pull_mb_samples(pull_samples)
        if out_file:
            exe_list, dll_list = get_zip_contents(out_file)
            print(exe_list)
            print(dll_list)
        sys.exit(0)


if __name__ == '__main__':
    main()
